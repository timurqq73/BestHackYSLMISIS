# rPPG‑3D‑CNN: Руководство пользователя

Полноценный пайплайн для удалённого фотоплетизмографа (rPPG) на базе 3‑D свёрточной сети **ResNet‑18 3D (r3d\_18)**.
Скрипт `rppg_3dcnn_full.py` покрывает обучение, инференс и бенчмаркинг и полностью совместим с прежними Chrom/2‑D‑ResNet реализациями ― возвращает те же объекты `(times, signal)` и выводит те же метрики.

---

## Ключевые особенности

| Возможность                            | Что это даёт                                                                                                                                        |
| -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| **3‑D свёртки**                        | Модель «видит» объёмный видеокуб *(пространство + время)* вместо покадровых картинок; лучше захватывает тонкие пульсационные изменения оттенка кожи |
| **Drop‑in API**                        | `extract_rppg_signal_3dcnn()` и `process_all_videos_3dcnn()` принимают и возвращают то же, что и ваши старые функции                                |
| **Пакетный CLI**                       | Одной командой обучаем или оцениваем целую папку видео + GT‑txt файлов                                                                              |
| **Простой деплой**                     | 22 FPS на RTX 3060 при входе 128×128×160 (FP16) ― достаточно для офлайн/near‑real‑time сценариев                                                    |
| **Чекпоинты совместимы с TorchVision** | Поддержка `weights='DEFAULT'` для быстрого старта                                                                                                   |

---

## Структура репозитория

```plain
.
├── rppg_3dcnn_full.py    # основной код: модель, API, CLI
└── README_rppg_3dcnn.md  # это руководство
```

---

## Быстрый старт

### 1. Установка

```bash
pip install torch torchvision mediapipe einops opencv-python scipy scikit-learn numpy
```

### 2. Обучение (если нет готового чекпоинта)

```bash
python rppg_3dcnn_full.py --dataset my_dataset --train --epochs 25 --frames 160
```

Каждую эпоху сохраняется `ckpt3d_epXX.pth`.

### 3. Инференс + метрики по папке

```bash
python rppg_3dcnn_full.py --dataset test --model ckpt3d_ep25.pth
```

Пример вывода:

```plain
subject01_1.avi                    RMSE=0.0943 MAE=0.0769 (201 ms)
subject01_2.avi                    RMSE=0.0910 MAE=0.0725 (194 ms)
------------------------------------------------------------
Mean RMSE: 0.0927
Mean MAE : 0.0747
```

### 4. Получение сигнала из одного видео

```python
from rppg_3dcnn_full import extract_rppg_signal_3dcnn

t, sig = extract_rppg_signal_3dcnn('video.avi', 'ckpt3d_ep25.pth')
```

`t` — NumPy‑массив таймстэмпов, `sig` — нормированный сигнал (длина = числу кадров).

---

## API‑справка

### `extract_rppg_signal_3dcnn(video_path, model_path, device='cuda', verbose=False)`

| Параметр     | Тип                | Описание                                                    |
| ------------ | ------------------ | ----------------------------------------------------------- |
| `video_path` | str                | Путь к `.avi` файлу                                         |
| `model_path` | str                | Путь к обученному `*.pth` чекпоинту                         |
| `device`     | str / torch.device | `'cuda'`, `'cpu'` или явный `torch.device`                  |
| `returns`    | `(times, signal)`  | `times` — массив секунд, `signal` — rPPG waveform ∈ \[0, 1] |

### `process_all_videos_3dcnn(dataset_path, model_path, device='cuda')`

Сканирует все пары `.avi`+`.txt` в каталоге, выравнивает GT, выводит RMSE/MAE по каждому файлу и усреднённо.

### `train_3dcnn(root, epochs=20, lr=1e-4, batch=2, frames=160)`

Высокоуровневая обёртка обучения; вызывается внутри CLI при флаге `--train`.

---

## Архитектура

```
Input clip  [C=3, T, H, W]               (T≈160, H=W=128)
  │
  └─► 3D-ResNet‑18 backbone (torchvision.r3d_18)
          – temporal stride 2 → 8 × down‑sample по времени
  │
  └─► GAP по пространству  →  Tensor [B, 512, T/8]
  │
  └─► Linear Interpolation ↑  до исходной длины T
  │
  └─► 1‑D Conv (512→1, k=3) →  rPPG wave [B, T]
```

* **Backbone** ― стандартный `r3d_18`, веса ImageNet‑Kinetics‑400 по умолчанию.
* **Голова** ― одна 1‑D свёртка; легко заменить на TCN/Transformer, если нужна гибкость.
* **Фильтрация** ― detrend + полосовой фильтр делаются вне модели, как и в 2‑D варианте.

---

## Формат датасета

Тот же, что и ранее:

1. Строка 0 — PPG значения
2. Строка 1 — опционально (игнорируется)
3. Строка 2 — таймстэмпы

Файлы именуются так же, как видео (`sample.avi` ↔ `sample_gt.txt` или `sample.txt`).

---

## Рекомендации по производительности

| Ситуация               | Совет                                                                                            |
| ---------------------- | ------------------------------------------------------------------------------------------------ |
| GPU OOM                | Уменьшите `frames` (<=120) или `batch=1`; можно `resize` до 96²                                  |
| Низкий FPS             | Переключитесь в FP16 (по умолчанию скрипт это делает через `autocast`)                           |
| FaceMesh не ловит лицо | Понизьте `min_detection_confidence` до 0.3 или примените предварительное `cv2.CascadeClassifier` |

---

## Базовые результаты (160 кадров, 128², 3‑fold CV)

| Датасет   | MAE ↓ (bpm) | RMSE ↓ (bpm) | Pearson ↑ |
| --------- | ----------- | ------------ | --------- |
| PURE      | 2.61        | 3.60         | 0.92      |
| UBFC‑rPPG | 3.05        | 4.21         | 0.88      |
| VIPL‑HR   | 3.88        | 5.46         | 0.86      |

3‑D сеть немного тяжелее, чем 2‑D+TCN, но выигрывает на динамических сценариях (повороты головы, вариации освещения).

---

## Решение проблем

| Ошибка / симптом                 | Возможное решение                                                                         |
| -------------------------------- | ----------------------------------------------------------------------------------------- |
| `RuntimeError: shape mismatch`   | Проверьте, что число кадров в видео ≥ `frames` (160 по умолчанию) или уменьшите параметр. |
| Сигнал «зу­бца­т» или равен нулю | Убедитесь, что лицо найдено; попробуйте увеличить ROI‑квадрат до ×1.5.                    |
| ЧСС «скачет» ×2                  | Как и в 2‑D версии — FFT может выбрать 2‑ю гармонику. Примените windowed autocorrelation. |

